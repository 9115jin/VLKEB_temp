alg_name: "IKE"
name: hugging_cache/opt-2.7b
model_name: blip2
model_class: Blip2OPT
tokenizer_class: GPT2Tokenizer
tokenizer_name: hugging_cache/opt-2.7b
sentence_model_name: hugging_cache/all-MiniLM-L6-v2
device: 0
results_dir: "./results"

k: 32

# Multimodal
task_name: "caption"
qformer_checkpoint: hugging_cache/blip2_pretrained_opt2.7b.pth
qformer_name_or_path: hugging_cache/bert-base-uncased
state_dict_file: hugging_cache/eva_vit_g.pth

# image
coco_image: datasets/VLKEB_images/mmkb_images
rephrase_image: datasets/VLKEB_images/mmkb_images