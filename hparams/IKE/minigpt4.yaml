alg_name: "IKE"
name: hugging_cache/vicuna-7b
model_name: minigpt4
model_class: Blip2OPT
tokenizer_class: LlamaTokenizer
tokenizer_name: hugging_cache/vicuna-7b
sentence_model_name: hugging_cache/all-MiniLM-L6-v2
device: 0
results_dir: "./results"

k: 32

# Multimodal
task_name: "caption"
qformer_checkpoint: hugging_cache/blip2_pretrained_flant5xxl.pth
qformer_name_or_path: hugging_cache/bert-base-uncased
state_dict_file: hugging_cache/eva_vit_g.pth
pretrained_ckpt: hugging_cache/pretrained_minigpt4_7b.pth

# image
coco_image: datasets/VLKEB_images/mmkb_images
rephrase_image: datasets/VLKEB_images/mmkb_images